{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from psycopg2 import connect\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from scipy.stats import variation\n",
    "from scipy import stats\n",
    "from pm4py.algo.discovery.dfg import algorithm as dfg_discovery\n",
    "from pm4py.visualization.dfg import visualizer as dfg_visualization\n",
    "from pm4py.statistics.eventually_follows.log import get as efg_get\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as sk\n",
    "from scipy.stats import chi2_contingency\n",
    "import math\n",
    "import statistics\n",
    "import pingouin as pg\n",
    "import graphviz\n",
    "from statsmodels.stats import multitest\n",
    "from statsmodels.stats.contingency_tables import SquareTable as ST\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Logs/MIMIC_Log_Raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"hadm_id\":\"case:hadm_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"Dialysis - CRRT\", \"Hemodialysis\", \"Non-invasive Ventilation\", \"Invasive Ventilation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_re = df.loc[df[\"concept:name\"].isin(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proc_re[\"time:timestamp\"] = proc_re[\"time:timestamp\"].apply(lambda x: pd.to_datetime(x))\n",
    "proc_re[\"endtime\"] = proc_re[\"endtime\"].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadms = list(proc_re[\"case:hadm_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_re = proc_re[[\"case:hadm_id\", \"time:timestamp\", \"endtime\", \"ordercategoryname\", \"category\", \"concept:name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_list = [\"Creatinine (serum)\", \"BUN\", \"Anion gap\", \"Hematocrit (serum)\", \"Heart Rate\", \"Respiratory Rate\", \"O2 saturation pulseoxymetry\", \"Non Invasive Blood Pressure systolic\", \"Non Invasive Blood Pressure diastolic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = df.loc[df[\"label\"].isin(marker_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas = meas.sort_values([\"case:hadm_id\", \"time:timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_log = meas.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_log[\"concept:name\"] = \"Measurement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_log = meas_log.drop_duplicates([\"case:hadm_id\", \"time:timestamp\", \"concept:name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_log = meas_log.loc[meas_log[\"case:hadm_id\"].isin(hadms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make endtime represented as second event\n",
    "proc_re = proc_re.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "\n",
    "for index, row in proc_re.iterrows():\n",
    "    r = row\n",
    "    r = r.drop(\"time:timestamp\", axis=\"index\")\n",
    "    r = r.rename({\"endtime\":\"time:timestamp\"})\n",
    "    r[\"concept:name\"] = \"END \" + r[\"concept:name\"]\n",
    "    rows_list.append(r)\n",
    "\n",
    "to_concat = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_start = proc_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_start[\"concept:name\"] = \"START \" + proc_start[\"concept:name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_start.drop(\"endtime\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_start_end = pd.concat([proc_start, to_concat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_start_end = proc_start_end.sort_values([\"case:hadm_id\", \"time:timestamp\"])\n",
    "proc_start_end = proc_start_end.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas_log = meas_log.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_proc_start_end = pd.concat([proc_start_end, meas_log])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_proc_start_end = chart_proc_start_end.sort_values([\"case:hadm_id\", \"time:timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meas[\"charttime\"] = meas[\"charttime\"].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate into category/value label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = meas[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link measurements to activities\n",
    "time_from_last_proc_event = pd.to_datetime(0)\n",
    "time_from_next_proc_event = pd.to_datetime(290, unit=\"Y\")\n",
    "rows_list = []\n",
    "for index, row in proc_start_end.iterrows():\n",
    "    row_to_add = {}\n",
    "    hadm_id = row[\"case:hadm_id\"]\n",
    "    act = row[\"concept:name\"]\n",
    "    if index == len(proc_start_end) - 1:\n",
    "        time_from_next_proc_event = pd.to_datetime(290, unit=\"Y\")\n",
    "    elif proc_start_end.iloc[index+1][\"case:hadm_id\"] == hadm_id:\n",
    "        time_from_next_proc_event = proc_start_end.iloc[index+1][\"time:timestamp\"]\n",
    "    else:\n",
    "        time_from_next_proc_event = pd.to_datetime(290, unit=\"Y\")\n",
    "    is_start = \"START\" in act\n",
    "    meas_p = meas.loc[meas[\"case:hadm_id\"] == hadm_id]\n",
    "    if is_start:\n",
    "        meas_p[\"time_delta\"] = row[\"time:timestamp\"] - meas_p[\"charttime\"]\n",
    "        meas_p = meas_p.loc[(meas_p[\"time_delta\"] > pd.Timedelta(0)) & (meas_p[\"charttime\"] > time_from_last_proc_event)]\n",
    "        row_to_add[\"concept:name\"] = \"Measurement\"\n",
    "    else:\n",
    "        meas_p[\"time_delta\"] = meas_p[\"charttime\"] - row[\"time:timestamp\"] \n",
    "        meas_p = meas_p.loc[(meas_p[\"time_delta\"] > pd.Timedelta(0)) & (meas_p[\"charttime\"] < time_from_next_proc_event)]\n",
    "        row_to_add[\"concept:name\"] = \"Measurement\"\n",
    "    row_to_add[\"case:hadm_id\"] = hadm_id\n",
    "    row_to_add[\"time:timestamp\"] = None\n",
    "    for lab in labels: \n",
    "        lab_val = meas_p.loc[meas_p[\"label\"] == lab]\n",
    "        try:\n",
    "            closest_val_index = lab_val[\"time_delta\"].idxmin()\n",
    "            closest_val_row = lab_val.loc[closest_val_index]\n",
    "            row_to_add[lab] = closest_val_row[\"valuenum\"]\n",
    "            if row_to_add[\"time:timestamp\"] is None:\n",
    "                row_to_add[\"time:timestamp\"] = closest_val_row[\"charttime\"]\n",
    "            if is_start:\n",
    "                if closest_val_row[\"charttime\"] > row_to_add[\"time:timestamp\"]:\n",
    "                    row_to_add[\"time:timestamp\"] = closest_val_row[\"charttime\"]\n",
    "            else: \n",
    "                if closest_val_row[\"charttime\"] < row_to_add[\"time:timestamp\"]:\n",
    "                    row_to_add[\"time:timestamp\"] = closest_val_row[\"charttime\"]\n",
    "        except:\n",
    "            row_to_add[lab] = None\n",
    "    if index == len(proc_start_end) -1:\n",
    "        time_from_last_proc_event = pd.to_datetime(0)\n",
    "    elif proc_start_end.iloc[index+1][\"case:hadm_id\"] == hadm_id:\n",
    "        time_from_last_proc_event = row[\"time:timestamp\"]\n",
    "    else:\n",
    "        time_from_last_proc_event = pd.to_datetime(0)\n",
    "    if row_to_add[\"time:timestamp\"] is not None:\n",
    "        rows_list.append(row_to_add)\n",
    "meas_events = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_log = pd.concat([proc_start_end, meas_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_log = final_log.sort_values([\"case:hadm_id\", \"time:timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_log.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time:timestamp\"] = df[\"time:timestamp\"].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadms = list(df[\"case:hadm_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"case:hadm_id\", \"time:timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {log_converter.Variants.TO_EVENT_LOG.value.Parameters.CASE_ID_KEY: 'case:hadm_id'}\n",
    "event_log = pm4py.format_dataframe(df, case_id='case:hadm_id', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "log = pm4py.convert_to_event_log(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = dfg_discovery.apply(log)\n",
    "dfg, sa, ea = pm4py.discover_directly_follows_graph(log)\n",
    "activities_count = pm4py.get_event_attribute_values(log, \"concept:name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = []\n",
    "for act in activities_count:\n",
    "    acts.append(act)\n",
    "real_acts = copy.deepcopy(acts)\n",
    "dfr_acts = copy.deepcopy(acts)\n",
    "dpr_acts = copy.deepcopy(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_Matrix = pd.DataFrame(columns=dfr_acts, index=dfr_acts)\n",
    "dpr_Matrix = pd.DataFrame(columns=dpr_acts, index=dpr_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr_activities_count = copy.deepcopy(activities_count)\n",
    "dpr_activities_count = copy.deepcopy(activities_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfr\n",
    "dfr_dict={}\n",
    "for act_1 in dfr_activities_count:\n",
    "    results = list()\n",
    "    for act_2 in dfr_activities_count:  \n",
    "        dfr_total = dfg[(act_1, act_2)]\n",
    "        act_count = activities_count[act_2]\n",
    "        res = dfr_total/act_count\n",
    "        dfr_Matrix.loc[act_1, act_2] = res\n",
    "        results.append(res)\n",
    "    dfr_dict[act_1] = results\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpr\n",
    "dpr_dict={}\n",
    "for act_1 in dpr_activities_count:\n",
    "    results = list()\n",
    "    for act_2 in dpr_activities_count:  \n",
    "        dpr_total = dfg[(act_2, act_1)]\n",
    "        act_count = activities_count[act_2]\n",
    "        res = dpr_total/act_count\n",
    "        dpr_Matrix.loc[act_1, act_2] = res\n",
    "        results.append(res)\n",
    "    dpr_dict[act_1] = results\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(columns=[\"sum\"], index=real_acts)\n",
    "for act in real_acts:\n",
    "    l_dfr = list(dfr_Matrix.loc[act])\n",
    "    l_dpr = list(dpr_Matrix.loc[act])\n",
    "    df_res.loc[act, \"sum\"] = (sum(l_dfr) + sum(l_dpr)) / ((len(real_acts)+1) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_context(events_to_transform, lambd):\n",
    "    mapping_before = {}\n",
    "    mapping_after = {}\n",
    "    for val in events_to_transform:\n",
    "        names_before = list(dfr_Matrix.loc[val].index)\n",
    "        names_after = list(dpr_Matrix.loc[val].index)\n",
    "        mapping_before[val] = []\n",
    "        mapping_after[val] = []\n",
    "        for index,rep_score in enumerate(dfr_Matrix.loc[val]):\n",
    "            if names_before[index] in events_to_transform or \"LacticAcid\" in names_before[index]:\n",
    "                continue\n",
    "            if rep_score > lambd:\n",
    "                mapping_before[val].append(names_before[index])\n",
    "        for index,rep_score in enumerate(dpr_Matrix.loc[val]):\n",
    "            if names_before[index] in events_to_transform or \"LacticAcid\" in names_before[index]:\n",
    "                continue\n",
    "            if rep_score > lambd:\n",
    "                mapping_after[val].append(names_after[index])\n",
    "    return mapping_before, mapping_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_transform = [\"Measurement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_before, mapping_after = identify_context(events_to_transform, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End OF Discovery and Context Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Event Transformation#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_event(df, rep_event, rep_mapping_before, rep_mapping_after):\n",
    "    rows_to_add_intern = []\n",
    "    row_to_add = {}\n",
    "    case_ids = list(df[\"case:hadm_id\"].unique())\n",
    "    for case_id in case_ids:\n",
    "        df_case = df.loc[df[\"case:hadm_id\"] == case_id]\n",
    "        #df_case = df_case.reset_index().drop(\"index\", axis=1)\n",
    "        for index, row in df_case.iterrows():\n",
    "            if row[\"concept:name\"] == rep_event:\n",
    "                try:\n",
    "                    if df_case.loc[index+1][\"concept:name\"] in rep_mapping_before:\n",
    "                        row_to_add = row\n",
    "                        row_to_add[\"concept:name\"] = row_to_add[\"concept:name\"] + \" BEFORE \" + df_case.loc[index+1][\"concept:name\"]\n",
    "                        row_to_add[\"event_time\"] = df_case.loc[index+1][\"time:timestamp\"]\n",
    "                        row_to_add[\"time_diff\"] = row_to_add[\"event_time\"] - row_to_add[\"time:timestamp\"]\n",
    "                        rows_to_add_intern.append(row_to_add)\n",
    "                    else:\n",
    "                        pass\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        \n",
    "        for index, row in df_case.iterrows():\n",
    "            if row[\"concept:name\"] == rep_event:\n",
    "                try:\n",
    "                    if df_case.loc[index-1][\"concept:name\"] in rep_mapping_after:\n",
    "                        row_to_add = row\n",
    "                        row_to_add[\"concept:name\"] = row_to_add[\"concept:name\"] + \" AFTER \" + df_case.loc[index-1][\"concept:name\"]\n",
    "                        row_to_add[\"event_time\"] = df_case.loc[index-1][\"time:timestamp\"]\n",
    "                        row_to_add[\"time_diff\"] = row_to_add[\"time:timestamp\"] - row_to_add[\"event_time\"]\n",
    "                        rows_to_add_intern.append(row_to_add)\n",
    "                    else:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "    rows_to_add_intern = pd.DataFrame(rows_to_add_intern)\n",
    "    rows_to_add_intern = rows_to_add_intern.sort_values([\"case:hadm_id\", \"time_diff\"])\n",
    "    rows_to_add_intern = rows_to_add_intern.drop_duplicates([\"case:hadm_id\", \"time:timestamp\"], keep=\"first\")\n",
    "    return rows_to_add_intern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_add = pd.DataFrame()\n",
    "df_new_rows = pd.DataFrame()\n",
    "for rep_event in events_to_transform:\n",
    "    df_e = df.copy()\n",
    "    for e in events_to_transform:\n",
    "        if e != rep_event:\n",
    "            df_e = df_e.loc[df_e[\"concept:name\"] != e]\n",
    "    df_e = df_e.sort_values([\"case:hadm_id\", \"time:timestamp\"])\n",
    "    df_e = df_e.reset_index().drop(\"index\", axis=1)\n",
    "    rows_to_add = transform_event(df_e, rep_event, mapping_before[rep_event], mapping_after[rep_event])\n",
    "    df_new_rows = pd.concat([df_new_rows, rows_to_add])\n",
    "new_df = df.copy()\n",
    "for rep_event in events_to_transform:\n",
    "    new_df = new_df.loc[new_df[\"concept:name\"] != rep_event]\n",
    "new_df = pd.concat([new_df, df_new_rows])\n",
    "new_df = new_df.sort_values([\"case:hadm_id\", \"time:timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"Logs/ICU_Log.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
